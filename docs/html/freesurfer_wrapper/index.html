<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>freesurfer_wrapper API documentation</title>
<meta name="description" content="freesurfer_wrapper
&gt; **freesurfer_wrapper** aims to facilitate the creation of a multiprocessing pipeline using FreeSurfer.
&gt; It is a Python wrapper …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>freesurfer_wrapper</code></h1>
</header>
<section id="section-intro">
<h1 id="freesurfer_wrapper">freesurfer_wrapper</h1>
<blockquote>
<p><strong>freesurfer_wrapper</strong> aims to facilitate the creation of a multiprocessing pipeline using FreeSurfer.
It is a Python wrapper to execute parallel runs of cross, base and long recon-all. Some pial edits algorithms are also available.</p>
</blockquote>
<h2 id="requirements">Requirements</h2>
<ul>
<li><a href="https://www.docker.com/">Docker</a></li>
<li><a href="https://surfer.nmr.mgh.harvard.edu/registration.html">FreeSurfer license key</a></li>
<li><a href="https://ubuntu.com/desktop">Ubuntu OS</a>: instructions are given, and were tested, considering an Ubuntu OS. It is possible to run using other OS, like Windows, since the wrapper uses Docker. However, keep in mind that adaptations may be necessary.</li>
</ul>
<h2 id="files-and-folders-overview">Files and folders overview</h2>
<pre><code>├── ADNI  # ADNI test data           
│   └── ...
├── docs # documentation files
│   └── ...
├── FS_OUTPUTS # output folder for processing (freesurfer SUBJECTS_DIR).
│
├── QC # output folder for quality control analysis
│
├── scripts # additional scripts used by the wrapper
│   └── ...
├── run.py # wrapper main script
</code></pre>
<h2 id="preparation">Preparation</h2>
<p>1) Place the license in a <code>license.txt</code> file in the same folder as the Dockerfile.</p>
<p>2) Place your dataset folder in the same folder as the Dockerfile.</p>
<p>3) Build the docker image:</p>
<pre><code class="language-bash">sudo docker build -t fs_wrapper .
</code></pre>
<h2 id="workflow-overview">Workflow overview</h2>
<p>In this section, a usage example is shown using data from the <a href="https://adni.loni.usc.edu/">Alzheimer's Disease Neuroimaging Initiative</a> dataset.
The <a href="ADNI">ADNI</a> folder contains MP-RAGE data from 3 visits of subject <code>137_S_1414</code>.</p>
<h3 id="recon-all-cross-processing">recon-all [CROSS] processing</h3>
<p>Cross-sectionally process all time points with the default workflow.</p>
<h4 id="input-file">Input file</h4>
<p>CROSS processing requires a tab separated file with named columns:</p>
<ul>
<li>Mandatory columns:</li>
<li>id: unique id.</li>
<li>
<p>dcm_path: path to one dcm/nii file.</p>
</li>
<li>
<p>Additional columns (<strong>required only in case of BASE and LONG processing</strong>):</p>
</li>
<li>subject: subject base ID</li>
<li>session: session ID</li>
<li>date: folder named with scan date</li>
<li>visit: time point relative to the ones contained in the subject folder.</li>
</ul>
<p>For the ADNI dataset example, you can create this file using <code>create_recon_input.py all -i &lt;PATH_TO_SAMPLES_FOLDER&gt;</code>. This will create a <code>recon_all_input.txt</code> file. The script will combine the subject ID and the session ID to create the unique ID.</p>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper python3 scripts/create_recon_input.py all -i ADNI/
</code></pre>
<p><code>recon_all_input.txt</code> example:</p>
<pre><code class="language-bash">id  subject session date    visit   dcm_path
137_S_1414_I64472   137_S_1414  I64472  2007-08-01_10_14_02.0   1   ADNI/137_S_1414/MP-RAGE/2007-08-01_10_14_02.0/I64472/ADNI_137_S_1414_MR_MP-RAGE__br_raw_20070803075521213_1_S36840_I64472.dcm
137_S_1414_I153787  137_S_1414  I153787 2009-08-26_11_06_33.0   2   ADNI/137_S_1414/MP-RAGE/2009-08-26_11_06_33.0/I153787/ADNI_137_S_1414_MR_MP-RAGE__br_raw_20090827101803061_1_S72806_I153787.dcm
137_S_1414_I190917  137_S_1414  I190917 2010-08-18_14_20_16.0   3   ADNI/137_S_1414/MP-RAGE/2010-08-18_14_20_16.0/I190917/ADNI_137_S_1414_MR_MP-RAGE__br_raw_20100819090950301_1_S90858_I190917.dcm
</code></pre>
<h4 id="run-recon-all-cross">Run recon-all [CROSS]</h4>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper python3 run.py recon_all -i recon_all_input.txt
</code></pre>
<p>This command will use the maximum number of CPUs. You can append the <code>-p &lt;INT&gt;</code> flag where <code>&lt;INT&gt;</code> is the number of parallel runs you want.</p>
<h3 id="recon-all-base-processing">recon-all [BASE] processing</h3>
<p>Create an unbiased template from all time points for each subject.</p>
<h4 id="input-file_1">Input file</h4>
<p>BASE processing requires a single column file were each line must be a command string with the following template:</p>
<p><code>recon-all -base &lt;subject&gt; -tp &lt;unique_id&gt; -tp &lt;unique_id&gt; ... -all</code></p>
<p>For the ADNI dataset example, you can create this file using <code>create_recon_input.py base -i recon_all_input.txt</code>. This will use the <code>recon_all_input.txt</code> file created previously for the CROSS processing. If necessary, edit this <code>recon_all_input.txt</code> to contain <strong>only the samples that have been successfully processed</strong>.</p>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper python3 scripts/create_recon_input.py base -i recon_all_input.txt
</code></pre>
<p><code>recon_base_input.txt</code> example:</p>
<pre><code class="language-bash">recon-all -base 137_S_1414 -tp 137_S_1414_I64472 -tp 137_S_1414_I153787 -tp 137_S_1414_I190917 -all
</code></pre>
<h4 id="run-recon-all-base">Run recon-all [BASE]</h4>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper python3 run.py recon_base -i recon_base_input.txt
</code></pre>
<p>This command will use the maximum number of CPUs. You can append the <code>-p &lt;INT&gt;</code> flag where <code>&lt;INT&gt;</code> is the number of parallel runs you want.</p>
<h3 id="recon-all-long-processing">recon-all [LONG] processing</h3>
<p>Longitudinally process all timepoints.</p>
<h4 id="input-file_2">Input file</h4>
<p>LONG processing requires a single column file were each line must be a command string with the following template:</p>
<p><code>recon-all -long &lt;unique_id&gt; &lt;subject&gt; -all</code></p>
<p>For the ADNI dataset example, you can create this file using <code>create_recon_input.py long -i recon_all_input.txt</code>. This will use the <code>recon_all_input.txt</code> file created previously for the CROSS processing. If necessary, edit this <code>recon_all_input.txt</code> to contain <strong>only the samples that have been successfully processed</strong>.</p>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper python3 scripts/create_recon_input.py long -i recon_all_input.txt
</code></pre>
<p><code>recon_long_input.txt</code> example:</p>
<pre><code class="language-bash">recon-all -long 137_S_1414_I64472 137_S_1414 -all
recon-all -long 137_S_1414_I153787 137_S_1414 -all
recon-all -long 137_S_1414_I190917 137_S_1414 -all
</code></pre>
<h4 id="run-recon-all-long">Run recon-all [LONG]</h4>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper python3 run.py recon_long -i recon_long_input.txt
</code></pre>
<p>This command will use the maximum number of CPUs. You can append the <code>-p &lt;INT&gt;</code> flag where <code>&lt;INT&gt;</code> is the number of parallel runs you want.</p>
<h3 id="segmentation-of-hippocampal-subfields-and-nuclei-of-the-amygdala-cross-processing">Segmentation of hippocampal subfields and nuclei of the amygdala [CROSS] processing</h3>
<p>Original script by Juan Eugenio Iglesias. For more information and citation requirements, please consult <a href="https://surfer.nmr.mgh.harvard.edu/fswiki/HippocampalSubfieldsAndNucleiOfAmygdala">FS official documentation</a>.</p>
<h4 id="input-file_3">Input file</h4>
<p>CROSS processing requires a tab separated file with named columns:</p>
<ul>
<li>Mandatory columns:</li>
<li>id: unique id.</li>
</ul>
<p>For the ADNI dataset example, you can use the <code>recon_all_input.txt</code> file created previously for the recon-all CROSS processing. If necessary, edit this <code>recon_all_input.txt</code> to contain <strong>only the samples that have been successfully processed</strong>.</p>
<h4 id="run-segment_ha-cross">Run segment_HA [CROSS]</h4>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper python3 run.py segment_HA -i recon_all_input.txt
</code></pre>
<p>This command will use the maximum number of CPUs. You can append the <code>-p &lt;INT&gt;</code> flag where <code>&lt;INT&gt;</code> is the number of parallel runs you want.</p>
<h3 id="segmentation-of-hippocampal-subfields-and-nuclei-of-the-amygdala-long-processing">Segmentation of hippocampal subfields and nuclei of the amygdala [LONG] processing</h3>
<p>Original script by Juan Eugenio Iglesias. For more information and citation requirements, please consult <a href="https://surfer.nmr.mgh.harvard.edu/fswiki/HippocampalSubfieldsAndNucleiOfAmygdala">FS official documentation</a>.</p>
<h4 id="input-file_4">Input file</h4>
<p>LONG processing requires a tab separated file with named columns:</p>
<ul>
<li>Mandatory columns:</li>
<li>subject: base ID from subject processed with recon-all [BASE]</li>
</ul>
<p>For the ADNI dataset example, you can use the <code>recon_all_input.txt</code> file created previously for the recon-all CROSS processing. If necessary, edit this <code>recon_all_input.txt</code> to contain <strong>only the samples that have been successfully processed</strong>.</p>
<h4 id="run-segment_ha-long">Run segment_HA [LONG]</h4>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper python3 run.py segment_HA_long -i recon_all_input.txt
</code></pre>
<p>This command will use the maximum number of CPUs. You can append the <code>-p &lt;INT&gt;</code> flag where <code>&lt;INT&gt;</code> is the number of parallel runs you want.</p>
<h2 id="tissue-ratio-correction">Tissue ratio correction</h2>
<p>After running <code>recon_all</code> you can check your results using <code>freeview</code>. Please refer to <a href="#manual-quality-analysis">Manual quality analysis section</a> to use a custom script.</p>
<p>If any skull edits are necessary, you need to create an input table to run <code>edit</code> with the following characteristics:</p>
<ul>
<li>Mandatory columns:</li>
<li>id: unique id.</li>
<li>ratio: the threshold to value (%) of WM intensity. The value should be &gt;0 and &lt;1; larger values would correspond to cleaner skull-strip but higher chance of brain erosion.</li>
</ul>
<p>You can copy the <code>recon_all_input.txt</code> content, keep only the lines for the scans that need edits, and add the column with the tissue ratio values.</p>
<p>As an example, an <code>edit_input.txt</code> file for some ADNI records would look like this:</p>
<pre><code class="language-bash">id  subject session date    visit   dcm_path    ratio
137_S_1414_I64472   137_S_1414  I64472  2007-08-01_10_14_02.0   1   ADNI/137_S_1414/MP-RAGE/2007-08-01_10_14_02.0/I64472/ADNI_137_S_1414_MR_MP-RAGE__br_raw_20070803075521213_1_S36840_I64472.dcm 0.5
137_S_1414_I153787  137_S_1414  I153787 2009-08-26_11_06_33.0   2   ADNI/137_S_1414/MP-RAGE/2009-08-26_11_06_33.0/I153787/ADNI_137_S_1414_MR_MP-RAGE__br_raw_20090827101803061_1_S72806_I153787.dcm 0.8
</code></pre>
<h3 id="run-edit">Run edit</h3>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper \
python3 run.py edit -i edit_input.txt
</code></pre>
<p>This command will use the maximum number of CPUs. You can append the <code>-p &lt;INT&gt;</code> flag where <code>&lt;INT&gt;</code> is the number of parallel runs you want.</p>
<p>You can check the resulting edited mask using <code>freeview</code>:</p>
<pre><code class="language-bash">SUBJECTS_DIR=$(pwd)/FS_OUTPUTS
freeview -recon &lt;UNIQUE_ID&gt; -v brainmask.gcutsT$&lt;TISSUE_RATIO&gt;.mgz:colormap=heat:opacity=0.5
</code></pre>
<p>If still not good, change the tissue ratio value in the input file and run <code>edit</code> again.
When all masks are OK, proceed to <code>recon_edit</code> command.</p>
<h3 id="recon_edit">recon_edit</h3>
<p><code>recon_edit</code> will re-run parts of FS recon-all using the edited masks.
The input file is the table used for <code>edit</code> with the final values for tissue ratio.</p>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper python3 run.py recon_edit -i edit_input.txt
</code></pre>
<p>This command will use the maximum number of CPUs. You can append the <code>-p &lt;INT&gt;</code> flag where <code>&lt;INT&gt;</code> is the number of parallel runs you want.</p>
<h2 id="how-to-check-for-completed-runs-and-hard-recon-all-errors">How to check for completed runs and hard recon-all errors</h2>
<p>FreeSurfer's recon-all command creates different logs while running.
The <code>recon-all.done</code> log is created only for completed runs. The <code>recon-all.error</code> is created for hard failures. </p>
<p>You can check these logs using a custom script. The script was written to work on ADNI folder structure. For other datasets you can try to edit the PATH_PATTERN variable in scripts/check_logs.py.</p>
<h3 id="done">Done</h3>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper \
python3 scripts/check_logs.py done
</code></pre>
<p>You can also pipe the output to bash word count command to get a quick count:</p>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper \
python3 scripts/check_logs.py done | wc -l
</code></pre>
<h3 id="error">Error</h3>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper \
python3 scripts/check_logs.py error
</code></pre>
<h2 id="how-to-restart-after-a-computer-failure">How to restart after a computer failure</h2>
<p>If the execution of the pipeline is halted by a computer failure or system restart then you have to update the input file of the <code>recon</code> commands.</p>
<p>To update <code>recon_all_input.txt</code>:</p>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper python3 scripts/update_recon_input.py all -i recon_all_input.txt
</code></pre>
<p>To update <code>recon_base_input.txt</code>:</p>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper python3 scripts/update_recon_input.py base -i recon_base_input.txt
</code></pre>
<p>To update <code>recon_long_input.txt</code>:</p>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper python3 scripts/update_recon_input.py long -i recon_long_input.txt
</code></pre>
<p>This will remove all "done" samples from the original input and create a new input file (<code>&lt;YYYY-MM-DD&gt;_recon_&lt;all|base|long&gt;_input.txt</code>).</p>
<p>To delete the folders from the samples that were running when the failure happened:</p>
<pre><code class="language-bash"># first check the list
IsRunning=(ls FS_OUTPUTS/*/scripts/*IsRunning* | cut -f 1,2 -d /)
echo $IsRunning

# if it is ok, delete
sudo rm -R $IsRunning
</code></pre>
<h2 id="quality-control">Quality control</h2>
<h3 id="automated-quality-analysis">Automated quality analysis</h3>
<p>The tool is packaged with <a href="https://github.com/Deep-MI/qatools-python"><strong>qatools-python</strong></a> version 1.2 for quality control measurements.
This script was developed by <a href="https://deep-mi.org/">Reuter DeepMI Lab</a> as a revision, extension, and translation to the Python language of the Freesurfer QA Tools.</p>
<pre><code class="language-bash">sudo docker run --rm -it -v &quot;$(pwd):/root/freesurfer_wrapper&quot; fs_wrapper \
python3 scripts/qatools-python/qatools.py --subjects_dir FS_OUTPUTS --output_dir QC \
--screenshots --outlier --fornix
</code></pre>
<p>This will create <code>qatools-results.csv</code> file; <code>screenshots</code>, <code>outliers</code> and <code>fornix</code> folders inside the QC folder. Please consult <a href="scripts/qatools-python/README.md#description">qatools-python docs</a> for a full explanation of each QC measurement.</p>
<h3 id="manual-quality-analysis">Manual quality analysis</h3>
<p>You can visually inspect each result using <code>freeview</code>. We provide a script to speed up the opening process of each scan.
The script also prompts the user about the result of the QC after each window of <code>freeview</code> is closed. The result is saved to manual_QC.txt</p>
<p>It is not possible to run <code>freeview</code> using Docker, the graphical user interface cannot be displayed. Therefore, you need to have FreeSurfer/freeview installed in your host machine.</p>
<h4 id="step-1">Step 1</h4>
<p>Set SUBJECTS_DIR environment variable. Here, the results are stored inside the FS_OUTPUTS directory.</p>
<pre><code class="language-bash">export SUBJECTS_DIR=$(pwd)/FS_OUTPUTS
</code></pre>
<h4 id="step-2">Step 2</h4>
<p>Run the <code>view.py</code> script.</p>
<pre><code class="language-bash">python3 scripts/view.py
</code></pre>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
.. include:: README.md
&#34;&#34;&#34;</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="freesurfer_wrapper.run" href="run.html">freesurfer_wrapper.run</a></code></dt>
<dd>
<div class="desc"><p>Command-line wrapper tool to execute parallel runs of FreeSurfer recon-all and some pial edits algorithms …</p></div>
</dd>
<dt><code class="name"><a title="freesurfer_wrapper.scripts" href="scripts/index.html">freesurfer_wrapper.scripts</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#freesurfer_wrapper">freesurfer_wrapper</a><ul>
<li><a href="#requirements">Requirements</a></li>
<li><a href="#files-and-folders-overview">Files and folders overview</a></li>
<li><a href="#preparation">Preparation</a></li>
<li><a href="#workflow-overview">Workflow overview</a><ul>
<li><a href="#recon-all-cross-processing">recon-all [CROSS] processing</a><ul>
<li><a href="#input-file">Input file</a></li>
<li><a href="#run-recon-all-cross">Run recon-all [CROSS]</a></li>
</ul>
</li>
<li><a href="#recon-all-base-processing">recon-all [BASE] processing</a><ul>
<li><a href="#input-file_1">Input file</a></li>
<li><a href="#run-recon-all-base">Run recon-all [BASE]</a></li>
</ul>
</li>
<li><a href="#recon-all-long-processing">recon-all [LONG] processing</a><ul>
<li><a href="#input-file_2">Input file</a></li>
<li><a href="#run-recon-all-long">Run recon-all [LONG]</a></li>
</ul>
</li>
<li><a href="#segmentation-of-hippocampal-subfields-and-nuclei-of-the-amygdala-cross-processing">Segmentation of hippocampal subfields and nuclei of the amygdala [CROSS] processing</a><ul>
<li><a href="#input-file_3">Input file</a></li>
<li><a href="#run-segment_ha-cross">Run segment_HA [CROSS]</a></li>
</ul>
</li>
<li><a href="#segmentation-of-hippocampal-subfields-and-nuclei-of-the-amygdala-long-processing">Segmentation of hippocampal subfields and nuclei of the amygdala [LONG] processing</a><ul>
<li><a href="#input-file_4">Input file</a></li>
<li><a href="#run-segment_ha-long">Run segment_HA [LONG]</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#tissue-ratio-correction">Tissue ratio correction</a><ul>
<li><a href="#run-edit">Run edit</a></li>
<li><a href="#recon_edit">recon_edit</a></li>
</ul>
</li>
<li><a href="#how-to-check-for-completed-runs-and-hard-recon-all-errors">How to check for completed runs and hard recon-all errors</a><ul>
<li><a href="#done">Done</a></li>
<li><a href="#error">Error</a></li>
</ul>
</li>
<li><a href="#how-to-restart-after-a-computer-failure">How to restart after a computer failure</a></li>
<li><a href="#quality-control">Quality control</a><ul>
<li><a href="#automated-quality-analysis">Automated quality analysis</a></li>
<li><a href="#manual-quality-analysis">Manual quality analysis</a><ul>
<li><a href="#step-1">Step 1</a></li>
<li><a href="#step-2">Step 2</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="freesurfer_wrapper.run" href="run.html">freesurfer_wrapper.run</a></code></li>
<li><code><a title="freesurfer_wrapper.scripts" href="scripts/index.html">freesurfer_wrapper.scripts</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>